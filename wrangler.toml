name = "ai-worker-proxy"
main = "src/index.ts"
compatibility_date = "2024-01-01"

# Cloudflare AI binding (optional)
[ai]
binding = "AI"

[vars]
# Proxy authentication token (can be overridden with secret)
PROXY_AUTH_TOKEN = "your-secret-proxy-token-here"

# Model routing configuration (JSON format)
# Each model name maps to an array of providers with fallback support
ROUTES_CONFIG = '''
{
  "deep-think": [
    {
      "provider": "anthropic",
      "model": "claude-opus-4-20250514",
      "apiKeys": ["ANTHROPIC_KEY_1", "ANTHROPIC_KEY_2"]
    },
    {
      "provider": "google",
      "model": "gemini-2.0-flash-thinking-exp-01-21",
      "apiKeys": ["GOOGLE_KEY_1"]
    }
  ],
  "fast": [
    {
      "provider": "google",
      "model": "gemini-2.0-flash-exp",
      "apiKeys": ["GOOGLE_KEY_1"]
    },
    {
      "provider": "cloudflare-ai",
      "model": "@cf/meta/llama-3.1-8b-instruct",
      "apiKeys": []
    }
  ],
  "nvidia": [
    {
      "provider": "openai-compatible",
      "baseUrl": "https://integrate.api.nvidia.com/v1",
      "model": "nvidia/llama-3.1-nemotron-70b-instruct",
      "apiKeys": ["NVIDIA_KEY_1", "NVIDIA_KEY_2"]
    }
  ],
  "openai": [
    {
      "provider": "openai",
      "model": "gpt-4o",
      "apiKeys": ["OPENAI_KEY_1"]
    }
  ]
}
'''

# Secrets (set these with: wrangler secret put <KEY_NAME>)
# - ANTHROPIC_KEY_1
# - ANTHROPIC_KEY_2
# - GOOGLE_KEY_1
# - NVIDIA_KEY_1
# - NVIDIA_KEY_2
# - OPENAI_KEY_1
# - PROXY_AUTH_TOKEN (optional override)
